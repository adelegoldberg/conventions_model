---
title: "Generalizing from individuals to populations: \\\ Hierarchical inference supports convention formation"
bibliography: library.bib
csl: apa6.csl
document-params: "10pt, letterpaper"

author-information: > 
    \author{{\large \bf Morton Ann Gernsbacher (MAG@Macc.Wisc.Edu)} \\ Department of Psychology, 1202 W. Johnson Street \\ Madison, WI 53706 USA
    \AND {\large \bf Sharon J.~Derry (SDJ@Macc.Wisc.Edu)} \\ Department of Educational Psychology, 1025 W. Johnson Street \\ Madison, WI 53706 USA}

abstract: >
   In this study, we collected experimental data showing how people conventionalize referring expressions in a series of interactive reference games with different partners in a small community. 
   Results were used to evaluate a hierarchical Bayesian cognitive model formalizing a theory of the generalization mechanisms underlying convention formation. 
    
keywords: >
    Add your choice of indexing terms or keywords; kindly use a semi-colon; between each term.
    
output: cogsci2016::cogsci_paper
#final-submission: \cogscifinalcopy
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=3, fig.height=3, fig.crop = F, 
                      fig.pos = "tb", fig.path='figs/',
                      echo=F, warning=F, cache=F, 
                      message=F, sanitize = T)
```

```{r, libraries}
library(grid)
library(tidyverse)
library(tidyboot)
library(ggthemes)
library(xtable)

clicks <- read_csv('../../data/clicks.csv')
messages <- read_csv('../../data/messages.csv')

completeNetworks <- clicks %>% 
  distinct() %>% group_by(networkid) %>% tally() %>% filter(n == 96) %>% pull(networkid)

numNetworks <- length(completeNetworks)

relevantMessages <- messages %>% 
  filter(role == "speaker") %>%
  filter(networkid %in% completeNetworks) %>%
  mutate(uttLength = str_count(content, " ") +1,
         repnum = floor(trialnum / 4)) %>%
  rowwise() %>%
  mutate(repnum = repnum + 1) %>%
  group_by(participantid, partnernum) %>%
  mutate(ordinalrep = ifelse(repnum == min(repnum), 'first', 'second')) %>%
  group_by(participantid, networkid, roomid, target, partnernum, repnum, ordinalrep) %>%
  summarize(m = sum(uttLength)) 
```

To communicate successfully, speakers and listeners must share a common system of semantic meaning in the language they are using. 
These meanings are *conventional* in the sense that they are sustained primarily by the expectations each agent has about others [@lewis_convention:_1969]. 
A key property of linguistic conventions is that they hold over an entire population, or community, allowing agents to communicate efficiently even with partners they've never met before. 
But exactly how do agents make the inferential leap to population-level expectations from their individual experiences with specific partners? 
Is this generalization made in one step, with agents assuming that any conventional meanings established with one partner will automatically be shared with others? 
Or does it require experience with multiple partners? 

Influential accounts of convention formation have appealed to simple, which may over time lead to emergent collective consensus [@baronchelli_emergence_2018, @fay_interactive_2010, @garrod_conversation_1994]. 

We propose
assumes that each agent has uncertainty over the system of meaning their current partner is using, and that they use Bayesian inference to update their beliefs about these meanings given observations of their partner’s language use and understanding. Critically, we also assume agents’ beliefs have hierarchical structure: the meanings used by different partners are expected to be sampled from a shared population-level distribution but may also differ from one another in meaningful ways. This structure provides an inductive pathway for abstract population-level expectations to be gradually distilled from partner-specific expectations. In other words, conventions result from solving a meta-learning problem.

While it has been frequently observed that messages reduce in length across repetitions with a single partner as the two partners establish local conventions through common ground, different accounts make different predictions at the partner boundary. 
Many previous agent-based models assume that agents do not distinguish one partner from another and completely transfer expectations from one partner to the next, which should result in no change in the number of words when a new partner is introduced. 
Another possibility is that there is no pooling across partners at all. 
This account predicts that agents must start from scratch establishing new partner-specific conventions with each new partner, resetting the initial description length anew with each interlocutor and never generalizing to the population-level. 
Contrary to either of these extremes, our hierarchical Bayesian model predicts that description length will increase at partner boundaries but that the initial length will decrease incrementally over successive interactions: after each partner, agents should be more willing to transfer expectations from one partner to another. 
Preliminary support for this signature was reported by [@fay_interactive_2010] in a Pictionary task where participants used sketches to communicate verbal concepts instead of using words to refer to visual targets, and the measure of interest was the complexity of the drawings [see also @garrod_conversation_1994].


# Model

```{r model_schematic, fig.env = "figure", fig.pos = "t", out.width = "250px", fig.height=1, fig.align = "center", set.cap.width=T, num.cols.cap=1, fig.cap = "Schematic of hierachical Bayesian model."}
knitr::include_graphics("figs/task1_model.pdf")
```



# Experiment

```{r task_display, fig.env = "figure*", fig.pos = "h", fig.width=4, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=2, fig.cap = "Experimental design. (A) Participants were placed in fully-connected networks of 4 and (B) played repeated reference games with each partner."}
knitr::include_graphics("figs/design.pdf")
```

## Methods

### Participants 

92 participants from Amazon Mechanical Turk were placed into `r numNetworks` fully-connected four-person networks. 

### Stimuli and procedure

<!-- One player (the speaker) provided descriptions target objects such that their partner (the listener) could choose it from an array of distractors.  -->
<!-- Each network was assigned four abstract tangram shapes taken from Clark & Wilkes-Gibbs (1986), and the trial sequence for a given partner was blocked so that each of the four objects appeared as the target four times.  -->
<!-- After completing all 16 trials with one partner, participants were introduced to a new partner and asked to play the same reference game again.  -->
<!-- This procedure was repeated until each participant had partnered with all three of their neighbors.  -->

Participants were paired with each of their three neighbors for a series of dyadic interactions. 
In each interaction, they played a real-time, natural-language reference game where they repeatedly referred to a set of four abstract tangram shapes taken from \citeA[Fig. \ref{fig:task1_display}]{clark_referring_1986}.
These stimuli have been used extensively in the literature on coordination and common ground [@duff_development_2006,@hawkins_convention-formation_2017].
They were designed such that participants will not already have strong pre-existing lexical conventions for how to refer to them (unlike photographs of common objects), but are structured enough to support many possible descriptions (unlike images of white noise).

On each trial of a reference game, one of these six shapes was highlighted as the \emph{target object} for the "speaker" who was instructed to use a chatbox to communicate the identity of this object to their partner, the "listener".
The listener could reply through the chatbox but must ultimately make a selection from the array. 
The trial sequence for a given partner was constructed so that each of four targets appear six times each, spread evenly across the session, for a total of 24 trials.

After completing 24 trials with one partner, they were introduced to their next partner and asked to play the repeated reference game again with the same four objects.
Each participant in a network was assigned a distinct avatar so that participants were clear they were speaking to distinct partners.
This process repeated until each participant had partnered with all five neighbors.
Players were given full feedback on each about their partner's choice and received bonus payment for each correct response. 
Because some pairs within the network took longer than others to complete the trial sequence, we sent participants to a temporary waiting room if their next partner was not yet ready. 


## Results

### Utterance length

```{r reduction, cache=T, fig.env = "figure", fig.pos = "h", fig.width=3, fig.height=2, fig.align = "center", set.cap.width=T, num.cols.cap=1, fig.cap = "Reduction in number of words within and across partner boundaries."}
relevantMessages %>%
  mutate(partnerlabel = paste0(c('partner #', partnernum + 1), collapse = "")) %>%
  group_by(partnerlabel, repnum) %>% 
  tidyboot::tidyboot_mean(column = m) %>%
  ggplot(aes(x = repnum, y = empirical_stat)) +
    geom_line() +
    geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper), alpha = .2) +
    facet_wrap(~ partnerlabel) +
    theme_few() +
    ylim(0,NA) +
    ylab("mean # words") +
    xlab("repetition with partner")
```

The key empirical predictions distinguishing our model from alternatives concern behavior across partner boundaries.
We operationalized the degree of conventionalization as the mean number of words used per description, a standard measure of coding efficiency in reference games (Krauss & Weinheimer, 1964). 


We tested these predictions using mixed-effects regressions of partner number and repetition number on the number of words in a speaker's description, with random-effect structure including item-effects at the object and speaker level. We find a positive jump in description length across partner-boundaries overall, t(91) = 3.7, p < 0.001, indicating sensitivity to different partners, but a successive incremental decrease in the lengths of these initial descriptions, t(79.2) = -6.8, p < 0.001, consistent with our proposal. These results suggest that hierarchical generalization may be a foundational cognitive building block for establishing conventionality at the group level.

### Convergence 

# Discussion


# Acknowledgements

Place acknowledgments (including funding information) in a section at
the end of the paper.

# References 

```{r}
# References will be generated automatically by Pandoc and included here.
# The following code is some latex to format the bibliography. Do not remove it.
```

\setlength{\parindent}{-0.1in} 
\setlength{\leftskip}{0.125in}
\noindent
