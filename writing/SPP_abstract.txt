To communicate successfully, speakers and listeners must share a common system of semantic meaning in the language they are using. These meanings are conventional in the sense that they are sustained primarily by the expectations each agent holds about the other (Lewis, 1969). A key property of linguistic conventions is that they are defined with respect to an entire population, or community, allowing agents to communicate even with partners they've never met before. Accounts of how such population-level conventions come to be shared in the first place typically appeal to distributed local interactions, which may over time lead to emergent collective consensus (Baronchelli, 2018; Fay et al, 2010; Garrod & Doherty, 1994). But on what basis can agents make the inferential leap to group-level expectations from their experience with particular partners? Here, we explore the idea that, from an agent's point of view, convention formation is a meta-learning problem. In particular, we formalize this idea in a hierarchical Bayesian model of a communicative agent with uncertainty over the meanings used by their partner and test the model's predicted patterns of generalization in an interactive reference game where participants learned how to communicate about a set of novel objects with a series of partners.

In this experiment, 92 participants from Amazon Mechanical Turk were assigned to fully-connected four-person networks, for a total of 23 networks. Participants were then paired with each of their three neighbors for a series of dyadic interactions, using a round-robin schedule. In each interaction, they played a real-time, natural-language reference game: one player (the speaker) provided descriptions of a target object such that their partner (the listener) could choose it from of an array of distractors. Each network was assigned one of three possible sets of four abstract tangram shapes taken from Clark & Wilkes-Gibbs (1986). These shapes were chosen because participants will not already have strong pre-existing linguistics conventions for how to refer to them (unlike photographs of common objects), but they are structured enough to support many possible conventions (unlike images of white noise). Players communicated through a chatbox, and while the listener was free to reply through the chatbox at any time, they advanced to the next trial when the listener made a selection from the array. The trial sequence for a given partner was constructed so that each of four targets appear four times each, spread evenly across the session, for a total of 16 trials. 

After completing 24 trials with one partner, they were introduced to their next partner and asked to play the repeated reference game again with the same four objects. Each participant in a network was assigned a distinct avatar so that participants were clear they were speaking to distinct partners. This process repeated until each participant had partnered with all three neighbors. Players were given full feedback on each about their partner's choice and received bonus payment for each correct response. Because some pairs within the network took longer than others to complete the trial sequence, we sent participants to a temporary waiting room if their next partner was not yet ready. 

The key dependent variable to test the predictions of our model against alternatives is the mean number of words used per description. This is a common operationalization of conventionalization in terms of coding efficiency. In particular, we were interested in how this measure changes within partners and across partner boundaries. While it has been frequently observed that messages reduce in length across repetitions with a single partner, as they coordinate on conventions, different accounts make different predictions at the partner boundary. Most agent-based models of convention emergence assume complete pooling: they predict that agents do not distinguish one partner from another and will therefore completely transfer expectations from the previous partner, leading to no change at all in the number of words used across different partners. Another possibility is that there is no pooling at all: partner-specific conventions form with each individual, but these expectations never generalize to the population level. This account predicts that agents must start from scratch coordinating with each partner and thus description length resets with every subsequent partner. Finally, our hierarchical account predicts that, the magnitude of the increase on partner boundaries will decrease over successive interactions: after several partners, agents should be more willing to transfer expectations form one partner to another.

We tested these predictions using a mixed-effects regression of partner number and repetition number the number of words in a speaker's description, with maximal random-effect structure including item-effects at the object and speaker level. First, we found a significant decrease in description length *within* each partner (XXX), but that ... 
